{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/tmp/flyte60hvpdje/user_space5v8my138/lifestreams'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /home/grantham/Desktop/windmark/notebooks/lightning_logs\n",
      "\n",
      "  | Name                   | Type                            | Params | In sizes                      | Out sizes              \n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | modular_field_embedder | ModularAttributeEmbeddingSystem | 70.2 K | [64]                          | [64, 8, 6, 12]         \n",
      "1 | field_encoder          | FieldEncoder                    | 52.0 K | [[64, 8, 6, 12], [512, 6, 6]] | [64, 8, 72]            \n",
      "2 | event_encoder          | EventEncoder                    | 1.3 M  | [[64, 8, 72], [64, 8, 8]]     | [[64, 72], [64, 8, 72]]\n",
      "3 | event_decoder          | EventDecoder                    | 425 K  | [64, 8, 72]                   | [64]                   \n",
      "4 | decision_head          | DecisionHead                    | 5.8 K  | [64, 72]                      | [64, 2]                \n",
      "5 | metrics                | ModuleDict                      | 0      | ?                             | ?                      \n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.310     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceModule(\n",
      "  (modular_field_embedder): ModularAttributeEmbeddingSystem(\n",
      "    (embedders): ModuleDict(\n",
      "      (use_chip): DiscreteFieldEmbedder(\n",
      "        (embeddings): Embedding(8, 12)\n",
      "      )\n",
      "      (merchant_state): DiscreteFieldEmbedder(\n",
      "        (embeddings): Embedding(132, 12)\n",
      "      )\n",
      "      (merchant_city): DiscreteFieldEmbedder(\n",
      "        (embeddings): Embedding(5549, 12)\n",
      "      )\n",
      "      (mcc): DiscreteFieldEmbedder(\n",
      "        (embeddings): Embedding(114, 12)\n",
      "      )\n",
      "      (amount): ContinuousFieldEmbedder(\n",
      "        (linear): Linear(in_features=16, out_features=12, bias=True)\n",
      "        (positional): Embedding(5, 12)\n",
      "      )\n",
      "      (timedelta): ContinuousFieldEmbedder(\n",
      "        (linear): Linear(in_features=16, out_features=12, bias=True)\n",
      "        (positional): Embedding(5, 12)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (field_encoder): FieldEncoder(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=12, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=12, bias=True)\n",
      "          (norm1): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (positional): LearnedTensor()\n",
      "  )\n",
      "  (event_encoder): EventEncoder(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-3): 4 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=72, out_features=72, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=72, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=72, bias=True)\n",
      "          (norm1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (positional): LearnedTensor()\n",
      "    (class_token): LearnedTensor()\n",
      "  )\n",
      "  (event_decoder): EventDecoder(\n",
      "    (projections): ModuleDict(\n",
      "      (use_chip): Conv1d(72, 8, kernel_size=(1,), stride=(1,))\n",
      "      (merchant_state): Conv1d(72, 132, kernel_size=(1,), stride=(1,))\n",
      "      (merchant_city): Conv1d(72, 5549, kernel_size=(1,), stride=(1,))\n",
      "      (mcc): Conv1d(72, 114, kernel_size=(1,), stride=(1,))\n",
      "      (amount): Conv1d(72, 13, kernel_size=(1,), stride=(1,))\n",
      "      (timedelta): Conv1d(72, 13, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (decision_head): DecisionHead(\n",
      "    (mlp): Sequential(\n",
      "      (0): Sequential(\n",
      "        (dense): Linear(in_features=72, out_features=64, bias=True)\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (dense): Linear(in_features=64, out_features=16, bias=True)\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (dense): Linear(in_features=16, out_features=4, bias=True)\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (dense): Linear(in_features=4, out_features=2, bias=True)\n",
      "        (act): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (metrics): ModuleDict(\n",
      "    (train_metrics): ModuleDict(\n",
      "      (ap): MulticlassAveragePrecision()\n",
      "      (f1): MulticlassF1Score()\n",
      "      (auc): MulticlassAUROC()\n",
      "      (acc): MulticlassAccuracy()\n",
      "    )\n",
      "    (validate_metrics): ModuleDict(\n",
      "      (ap): MulticlassAveragePrecision()\n",
      "      (f1): MulticlassF1Score()\n",
      "      (auc): MulticlassAUROC()\n",
      "      (acc): MulticlassAccuracy()\n",
      "    )\n",
      "    (test_metrics): ModuleDict(\n",
      "      (ap): MulticlassAveragePrecision()\n",
      "      (f1): MulticlassF1Score()\n",
      "      (auc): MulticlassAUROC()\n",
      "      (acc): MulticlassAccuracy()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "setting up for stage TrainerFn.FITTING\n",
      "Epoch 1: |          | 16/? [00:02<00:00,  6.05it/s, v_num=0]               "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grantham/.cache/pypoetry/virtualenvs/windmark-XVYwV8Ge-py3.11/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name                   | Type                            | Params | In sizes                      | Out sizes              \n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | modular_field_embedder | ModularAttributeEmbeddingSystem | 70.2 K | [64]                          | [64, 8, 6, 12]         \n",
      "1 | field_encoder          | FieldEncoder                    | 52.0 K | [[64, 8, 6, 12], [512, 6, 6]] | [64, 8, 72]            \n",
      "2 | event_encoder          | EventEncoder                    | 1.3 M  | [[64, 8, 72], [64, 8, 8]]     | [[64, 72], [64, 8, 72]]\n",
      "3 | event_decoder          | EventDecoder                    | 425 K  | [64, 8, 72]                   | [64]                   \n",
      "4 | decision_head          | DecisionHead                    | 5.8 K  | [64, 72]                      | [64, 2]                \n",
      "5 | metrics                | ModuleDict                      | 0      | ?                             | ?                      \n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.310     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up for stage TrainerFn.FITTING\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 14.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grantham/Desktop/windmark/source/core/architecture.py:641: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logits = torch.nn.functional.softmax(representations)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grantham/.cache/pypoetry/virtualenvs/windmark-XVYwV8Ge-py3.11/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Average precision score for one or more classes was `nan`. Ignoring these classes in macro-average\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/home/grantham/.cache/pypoetry/virtualenvs/windmark-XVYwV8Ge-py3.11/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/home/grantham/.cache/pypoetry/virtualenvs/windmark-XVYwV8Ge-py3.11/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: |          | 10/? [00:02<00:00,  4.64it/s, v_num=1]"
     ]
    }
   ],
   "source": [
    "from tdigest import TDigest\n",
    "from lightning.pytorch import Trainer\n",
    "\n",
    "from source.core import Hyperparameters, SequenceModule\n",
    "from source.core.schema import Field\n",
    "\n",
    "fields = [\n",
    "    Field(name='use_chip', dtype='discrete', n_levels=3),\n",
    "    Field(name='merchant_state', dtype='discrete', n_levels=127),\n",
    "    Field(name='merchant_city', dtype='discrete', n_levels=5544),\n",
    "    Field(name='mcc', dtype='discrete', n_levels=109),\n",
    "    Field(name='amount', dtype='continuous'),\n",
    "    Field(name='timedelta', dtype='continuous'),\n",
    "]\n",
    "\n",
    "params = Hyperparameters(fields=fields)\n",
    "\n",
    "\n",
    "module = SequenceModule(\n",
    "    datapath=path,\n",
    "    params=params,\n",
    "    digests=dict(\n",
    "        amount=TDigest(),\n",
    "        timedelta=TDigest(),\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(module)\n",
    "\n",
    "trainer = Trainer(accelerator=\"cpu\")\n",
    "trainer.fit(module)\n",
    "\n",
    "module.mode = 'finetune'\n",
    "trainer = Trainer(accelerator=\"cpu\")\n",
    "trainer.fit(module)\n",
    "\n",
    "\n",
    "# module.loaders()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "windmark-XVYwV8Ge-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
