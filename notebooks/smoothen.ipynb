{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0576, 0.2583, 0.4258, 0.2583]],\n",
      "\n",
      "        [[0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5705, 0.3460, 0.0772, 0.0063],\n",
      "         [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def smoothen(\n",
    "    labels: Int[torch.Tensor, \"N L\"],\n",
    "    n_quantiles: int,\n",
    "    sigma: float,\n",
    "    threshold: int\n",
    ") -> Float[torch.Tensor, \"N L ?\"]:\n",
    "\n",
    "    device = labels.device\n",
    "\n",
    "    N, L = labels.size()\n",
    "\n",
    "    range_tensor = torch.arange(0, n_quantiles+threshold, device=device).float()\n",
    "    \n",
    "    # expand and reshape to match the batch and sequence dimensions\n",
    "    range_tensor = range_tensor.unsqueeze(0).unsqueeze(0).expand(N, L, n_quantiles+threshold)\n",
    "    labels_expanded = labels.float().unsqueeze(-1)\n",
    "    \n",
    "    # create gaussian distribution for each label in the sequence\n",
    "    gaussian = torch.exp(-0.5 * ((range_tensor - labels_expanded) ** 2) / sigma**2)\n",
    "    gaussian /= gaussian.sum(dim=-1, keepdim=True)\n",
    "    \n",
    "    # one-hot encoding for labels at or below the threshold\n",
    "    one_hot = torch.zeros_like(gaussian).scatter_(-1, labels.unsqueeze(-1), 1.0)\n",
    "    \n",
    "    # determine which labels are above the threshold\n",
    "    is_above_threshold = labels > threshold\n",
    "    \n",
    "    # prevent gaussian bleeding for labels above the threshold\n",
    "    start_bleed = torch.zeros_like(labels, dtype=torch.float32) + threshold + 1\n",
    "    start_positions = torch.where(is_above_threshold, start_bleed, labels.float())\n",
    "    prevent_bleed_mask = range_tensor >= start_positions.unsqueeze(-1)\n",
    "    \n",
    "    # re-normalize\n",
    "    gaussian_masked = gaussian * prevent_bleed_mask.float()\n",
    "    gaussian_masked /= gaussian_masked.sum(dim=-1, keepdim=True)\n",
    "    \n",
    "    # combine using the condition\n",
    "    return torch.where(is_above_threshold.unsqueeze(-1), gaussian_masked, one_hot)\n",
    "\n",
    "# Example usage\n",
    "n_quantiles = 5  # Assuming 5 quantile bins\n",
    "labels = torch.tensor([[0, 2, 3, 6], [1, 2, 4, 3]])  # Example labels for a sequence on GPU\n",
    "sigma = 1.0  # Smoothing parameter\n",
    "threshold = 3  # Only smooth labels above this threshold\n",
    "\n",
    "smoothed_labels = smoothen(labels, n_quantiles, sigma, threshold)\n",
    "print(smoothed_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "windmark-gThMBSDt-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
