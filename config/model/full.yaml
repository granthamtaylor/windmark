n_pretrain_steps: 300
n_finetune_steps: 100
n_context: 300
batch_size: 128
d_field: 56
max_pretrain_epochs: 128
max_finetune_epochs: 4
n_layers_event_encoder: 4
n_epochs_frozen: 2
n_heads_event_encoder: 8
n_layers_field_encoder: 1
n_heads_field_encoder: 8
learning_rate: 0.00005
quantile_smoothing: 0.001
n_quantiles: 32
p_mask_event: 0.075
p_mask_field: 0.075
p_mask_static: 0.25
dropout: 0.1
patience: 4
