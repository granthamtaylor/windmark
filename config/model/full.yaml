n_pretrain_steps: 192
n_finetune_steps: 96
n_context: 384
batch_size: 128
d_field: 64
max_pretrain_epochs: 960
max_finetune_epochs: 960
n_layers_field_encoder: 1
n_heads_field_encoder: 8
n_layers_event_encoder: 4
n_heads_event_encoder: 8
n_epochs_frozen: 32
learning_rate: 0.000005
quantile_smoothing: 1.0
n_quantiles: 64
p_mask_event: 0.075
p_mask_field: 0.075
p_mask_static: 0.25
dropout: 0.10
patience: 32
