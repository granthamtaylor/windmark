n_pretrain_steps: 512
n_finetune_steps: 192
n_context: 128
batch_size: 128
d_field: 64
max_pretrain_epochs: 960
max_finetune_epochs: 960
n_layers_field_encoder: 1
n_heads_field_encoder: 8
n_layers_event_encoder: 8
n_heads_event_encoder: 8
n_epochs_frozen: 2
learning_rate: 0.00005
quantile_smoothing: 1.0
n_quantiles: 32
p_mask_event: 0.075
p_mask_field: 0.075
p_mask_static: 0.05
dropout: 0.1
patience: 32
