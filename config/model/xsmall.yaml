n_pretrain_steps: 512
n_finetune_steps: 72
n_context: 32
batch_size: 256
d_field: 64
max_pretrain_epochs: 512
max_finetune_epochs: 512
n_layers_field_encoder: 1
n_heads_field_encoder: 8
n_layers_event_encoder: 6
n_heads_event_encoder: 8
n_epochs_frozen: 8
learning_rate: 0.00001
quantile_smoothing: 1.0
n_quantiles: 32
p_mask_event: 0.08
p_mask_field: 0.08
p_mask_static: 0.05
dropout: 0.1
patience: 64
